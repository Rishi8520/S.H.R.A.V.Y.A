#include "hal_data.h"
#include "eegTYPES.h"
#include "shravyaCONFIG.h"
#include "signalPROCESSING.h"
#include "semaphoresGLOBAL.h"
#include "cognitiveSTATES.h"
#include "communicationN8N.h"
//#include "mtk3_bsp2/include/tk/tkernel.h"
#include <math.h>     // For sinf(), cosf(), fabsf(), sqrtf()
#include <string.h>   // For memset(), memmove()

#include <stdio.h>    // For printf()
#include <string.h>   // For memset(), strcpy()

#ifndef INT
typedef int INT;
#endif
#ifndef ER
typedef int ER;
#endif
#ifndef ID
typedef int ID;
#endif
#ifndef E_OK
#define E_OK (0)
#endif
#ifndef TMO_FEVR
#define TMO_FEVR (-1)           // Wait forever
#endif
#ifndef E_TMOUT
#define E_TMOUT (-7)    /* Timeout error */
#endif

/* ✅ Missing FSP Error Codes */
#ifndef FSP_ERR_NOT_READY
#define FSP_ERR_NOT_READY (-12) // Standard FSP error code
#endif
#ifndef FSP_ERR_INVALID_POINTER
#define FSP_ERR_INVALID_POINTER (-6)
#endif

/* ✅ μT-Kernel Function Prototypes */
extern ER tk_wai_sem(ID semid, INT timeout);
extern ER tk_sig_sem(ID semid, INT cnt);
extern ER tk_dly_tsk(INT dlytim);
extern ID preprocessing_semaphore;
// ✅ External structures and variables from cognitive classifier
extern feature_vector_t current_features;  // ✅ This is the missing variable!

// ✅ External function declarations from cognitive classifier
extern void extract_frequency_features(const float *left_signal, const float *right_signal, int size);
extern void extract_time_domain_features(const float *left_signal, const float *right_signal, int size);
extern void extract_coherence_features(const float *left_signal, const float *right_signal, int size);
extern void extract_quality_features(const float *left_signal, const float *right_signal, int size);


/* DSP Constants */
#define PI                          3.14159265358979323846f
#define TWOPI                       6.28318530717958647692f
#define SQRT2                       1.41421356237309504880f

/* Filter Parameters */
#define NOTCH_FREQ_50HZ             50.0f
#define NOTCH_FREQ_60HZ             60.0f
#define NOTCH_BANDWIDTH             2.0f
#define BANDPASS_LOW_CUTOFF         0.5f    // EEG lower bound
#define BANDPASS_HIGH_CUTOFF        45.0f   // EEG upper bound
#define FILTER_ORDER                4       // 4th order filters

/* Artifact Detection Thresholds */
#define AMPLITUDE_THRESHOLD_UV      150.0f  // ±150μV amplitude limit
#define GRADIENT_THRESHOLD          50.0f   // Max gradient between samples
#define SATURATION_THRESHOLD        0x7F0000 // 24-bit ADC near saturation
#define BASELINE_DRIFT_THRESHOLD    20.0f   // Baseline drift limit

/* Processing Window Sizes */
#define PROCESSING_WINDOW_SIZE      5     // 512ms at 500Hz (power of 2)
#define OVERLAP_SIZE               1     // 50% overlap
#define ARTIFACT_HISTORY_SIZE      10      // Track last 10 windows
// ✅ Add these defines at the top of signalPROCESSING.c
#define OUTPUT_LAYER_SIZE 6

// ✅ Add these cognitive state enums
#define COGNITIVE_STATE_FOCUS 0
#define COGNITIVE_STATE_CALM 1
#define COGNITIVE_STATE_STRESS 2
#define COGNITIVE_STATE_ANXIETY 3
#define COGNITIVE_STATE_FATIGUE 4
#define COGNITIVE_STATE_EXCITED 5


/* IIR Filter Structure (Biquad sections) */
typedef struct {
    float b0, b1, b2;  // Numerator coefficients
    float a1, a2;      // Denominator coefficients (a0 = 1.0)
    float x1, x2;      // Input history
    float y1, y2;      // Output history
} biquad_filter_t;

/* Complete Filter Bank */
typedef struct {
    biquad_filter_t notch_50hz[2];      // 50Hz notch (2 cascaded biquads)
    biquad_filter_t notch_60hz[2];      // 60Hz notch (2 cascaded biquads)
    biquad_filter_t highpass[2];        // 0.5Hz highpass (2 cascaded biquads)
    biquad_filter_t lowpass[2];         // 45Hz lowpass (2 cascaded biquads)
} eeg_filter_bank_t;

/* Signal Processing State */
typedef struct {
    eeg_filter_bank_t left_filters;
    eeg_filter_bank_t right_filters;
    float processing_buffer_left[PROCESSING_WINDOW_SIZE];
    float processing_buffer_right[PROCESSING_WINDOW_SIZE];
    uint32_t buffer_index;
    bool buffer_ready;
    uint32_t artifact_count[ARTIFACT_HISTORY_SIZE];
    uint32_t artifact_index;
    float baseline_left;
    float baseline_right;
    uint32_t samples_processed;
} signal_processing_state_t;

/* Global Variables */
static signal_processing_state_t processing_state;
static volatile bool processing_initialized = false;
void process_eeg_samples_direct(void);

/* External semaphore references */
extern ID preprocessing_semaphore;
extern ID feature_extraction_semaphore;

/* Private Function Prototypes */
static void init_biquad_filter(biquad_filter_t *filter, float b0, float b1, float b2, float a1, float a2);
static void design_notch_filter(biquad_filter_t filters[2], float freq_hz, float sample_rate_hz, float bandwidth);
static void design_highpass_filter(biquad_filter_t filters[2], float cutoff_hz, float sample_rate_hz);
static void design_lowpass_filter(biquad_filter_t filters[2], float cutoff_hz, float sample_rate_hz);
static float process_biquad_cascade(biquad_filter_t filters[2], float input);
static void init_filter_bank(eeg_filter_bank_t *bank);
static float convert_adc_to_voltage(int32_t adc_value);
static bool detect_artifacts(float left_sample, float right_sample, float prev_left, float prev_right);
static void update_baseline(float left_sample, float right_sample);
static void apply_signal_conditioning(float *left_sample, float *right_sample);
void task_signal_processing_entry(INT stacd, void *exinf);

extern ER tk_sus_tsk(ID tskid);
extern ER tk_rsm_tsk(ID tskid);
extern ER tk_rel_wai(void);
extern ID tk_get_tid(void);
// External functions from cognitive classifier
extern void forward_propagation(const feature_vector_t *features, float *output);
extern cognitive_state_type_t determine_dominant_state(const float *probabilities);
extern bool intervention_required(const cognitive_classification_t *result);
extern void handle_intervention_trigger(cognitive_classification_t *result);

// External functions from N8N communication
extern void build_n8n_json_payload(const n8n_eeg_payload_t *payload, char *buffer, size_t buffer_size);
extern fsp_err_t send_to_n8n_webhook(const char *json_data);


/**
 * @brief Initialize signal processing system
 */
fsp_err_t signal_processing_init(void)
{
    /* Clear processing state */
    memset(&processing_state, 0, sizeof(processing_state));

    /* Initialize filter banks for both channels */
    init_filter_bank(&processing_state.left_filters);
    init_filter_bank(&processing_state.right_filters);

    /* Initialize baseline estimates */
    processing_state.baseline_left = 0.0f;
    processing_state.baseline_right = 0.0f;
    processing_state.buffer_index = 0;
    processing_state.buffer_ready = false;
    processing_state.artifact_index = 0;
    processing_state.samples_processed = 0;

    processing_initialized = true;

    return FSP_SUCCESS;
}

/**
 * @brief Initialize complete filter bank
 */
static void init_filter_bank(eeg_filter_bank_t *bank)
{
    /* Design 50Hz notch filter (2nd order, cascaded for 4th order) */
    design_notch_filter(bank->notch_50hz, NOTCH_FREQ_50HZ, EEG_SAMPLE_RATE_HZ, NOTCH_BANDWIDTH);

    /* Design 60Hz notch filter (2nd order, cascaded for 4th order) */
    design_notch_filter(bank->notch_60hz, NOTCH_FREQ_60HZ, EEG_SAMPLE_RATE_HZ, NOTCH_BANDWIDTH);

    /* Design highpass filter for DC blocking (0.5Hz cutoff) */
    design_highpass_filter(bank->highpass, BANDPASS_LOW_CUTOFF, EEG_SAMPLE_RATE_HZ);

    /* Design lowpass filter for anti-aliasing (45Hz cutoff) */
    design_lowpass_filter(bank->lowpass, BANDPASS_HIGH_CUTOFF, EEG_SAMPLE_RATE_HZ);
}

/**
 * @brief Design notch filter using biquad sections
 */
static void design_notch_filter(biquad_filter_t filters[2], float freq_hz, float sample_rate_hz, float bandwidth)
{
    float omega = TWOPI * freq_hz / sample_rate_hz;
    float alpha = sinf(omega) * sinhf(logf(2.0f) / 2.0f * bandwidth * omega / sinf(omega));
    float cos_omega = cosf(omega);

    /* Notch filter coefficients */
    float b0 = 1.0f;
    float b1 = -2.0f * cos_omega;
    float b2 = 1.0f;
    float a0 = 1.0f + alpha;
    float a1 = -2.0f * cos_omega;
    float a2 = 1.0f - alpha;

    /* Normalize coefficients */
    b0 /= a0;
    b1 /= a0;
    b2 /= a0;
    a1 /= a0;
    a2 /= a0;

    /* Initialize first biquad */
    init_biquad_filter(&filters[0], b0, b1, b2, a1, a2);

    /* Second biquad identical for steeper rolloff */
    init_biquad_filter(&filters[1], b0, b1, b2, a1, a2);
}

/**
 * @brief Design highpass filter using biquad sections
 */
static void design_highpass_filter(biquad_filter_t filters[2], float cutoff_hz, float sample_rate_hz)
{
    float omega = TWOPI * cutoff_hz / sample_rate_hz;
    float alpha = sinf(omega) / SQRT2; // Q = 0.707 for Butterworth
    float cos_omega = cosf(omega);

    /* Highpass filter coefficients */
    float b0 = (1.0f + cos_omega) / 2.0f;
    float b1 = -(1.0f + cos_omega);
    float b2 = (1.0f + cos_omega) / 2.0f;
    float a0 = 1.0f + alpha;
    float a1 = -2.0f * cos_omega;
    float a2 = 1.0f - alpha;

    /* Normalize coefficients */
    b0 /= a0;
    b1 /= a0;
    b2 /= a0;
    a1 /= a0;
    a2 /= a0;

    /* Initialize cascaded biquads */
    init_biquad_filter(&filters[0], b0, b1, b2, a1, a2);
    init_biquad_filter(&filters[1], b0, b1, b2, a1, a2);
}

/**
 * @brief Design lowpass filter using biquad sections
 */
static void design_lowpass_filter(biquad_filter_t filters[2], float cutoff_hz, float sample_rate_hz)
{
    float omega = TWOPI * cutoff_hz / sample_rate_hz;
    float alpha = sinf(omega) / SQRT2; // Q = 0.707 for Butterworth
    float cos_omega = cosf(omega);

    /* Lowpass filter coefficients */
    float b0 = (1.0f - cos_omega) / 2.0f;
    float b1 = 1.0f - cos_omega;
    float b2 = (1.0f - cos_omega) / 2.0f;
    float a0 = 1.0f + alpha;
    float a1 = -2.0f * cos_omega;
    float a2 = 1.0f - alpha;

    /* Normalize coefficients */
    b0 /= a0;
    b1 /= a0;
    b2 /= a0;
    a1 /= a0;
    a2 /= a0;

    /* Initialize cascaded biquads */
    init_biquad_filter(&filters[0], b0, b1, b2, a1, a2);
    init_biquad_filter(&filters[1], b0, b1, b2, a1, a2);
}

/**
 * @brief Initialize biquad filter structure
 */
static void init_biquad_filter(biquad_filter_t *filter, float b0, float b1, float b2, float a1, float a2)
{
    filter->b0 = b0;
    filter->b1 = b1;
    filter->b2 = b2;
    filter->a1 = a1;
    filter->a2 = a2;
    filter->x1 = 0.0f;
    filter->x2 = 0.0f;
    filter->y1 = 0.0f;
    filter->y2 = 0.0f;
}

/**
 * @brief Process input through cascaded biquad filters
 */
static float process_biquad_cascade(biquad_filter_t filters[2], float input)
{
    /* Process through first biquad */
    float output1 = filters[0].b0 * input + filters[0].b1 * filters[0].x1 + filters[0].b2 * filters[0].x2
                   - filters[0].a1 * filters[0].y1 - filters[0].a2 * filters[0].y2;

    /* Update first biquad history */
    filters[0].x2 = filters[0].x1;
    filters[0].x1 = input;
    filters[0].y2 = filters[0].y1;
    filters[0].y1 = output1;

    /* Process through second biquad */
    float output2 = filters[1].b0 * output1 + filters[1].b1 * filters[1].x1 + filters[1].b2 * filters[1].x2
                   - filters[1].a1 * filters[1].y1 - filters[1].a2 * filters[1].y2;

    /* Update second biquad history */
    filters[1].x2 = filters[1].x1;
    filters[1].x1 = output1;
    filters[1].y2 = filters[1].y1;
    filters[1].y1 = output2;

    return output2;
}

/**
 * @brief Convert 24-bit ADC value to voltage in microvolts
 */
static float convert_adc_to_voltage(int32_t adc_value)
{
    /* ADS1263 with 2.5V reference, PGA gain = 32, 24-bit resolution */
    /* Full scale = ±2.5V / 32 = ±78.125mV */
    /* LSB = 78125μV / 8388608 = 9.31μV per LSB */

    return ((float)adc_value * 78125.0f) / 8388608.0f;
}

/**
 * @brief Detect various types of artifacts in EEG signals
 */
static bool detect_artifacts(float left_sample, float right_sample, float prev_left, float prev_right)
{
    /* Check for amplitude saturation */
    if (fabsf(left_sample) > AMPLITUDE_THRESHOLD_UV || fabsf(right_sample) > AMPLITUDE_THRESHOLD_UV)
    {
        return true;
    }

    /* Check for excessive gradient (muscle artifacts, movement) */
    float left_gradient = fabsf(left_sample - prev_left);
    float right_gradient = fabsf(right_sample - prev_right);

    if (left_gradient > GRADIENT_THRESHOLD || right_gradient > GRADIENT_THRESHOLD)
    {
        return true;
    }

    /* Check for common-mode artifacts (both channels similar high amplitude) */
    if (fabsf(left_sample) > 50.0f && fabsf(right_sample) > 50.0f)
    {
        float correlation = (left_sample * right_sample) / (fabsf(left_sample) * fabsf(right_sample));
        if (correlation > 0.8f) // High correlation suggests common-mode noise
        {
            return true;
        }
    }

    return false;
}

/**
 * @brief Update baseline estimates using adaptive filter
 */
static void update_baseline(float left_sample, float right_sample)
{
    /* Simple adaptive baseline with 0.99 forgetting factor */
    const float alpha = 0.001f; // Adaptation rate

    processing_state.baseline_left = (1.0f - alpha) * processing_state.baseline_left + alpha * left_sample;
    processing_state.baseline_right = (1.0f - alpha) * processing_state.baseline_right + alpha * right_sample;
}

/**
 * @brief Apply additional signal conditioning
 */
static void apply_signal_conditioning(float *left_sample, float *right_sample)
{
    /* Remove baseline drift */
    *left_sample -= processing_state.baseline_left;
    *right_sample -= processing_state.baseline_right;

    /* Apply soft limiting to prevent excessive values */
    const float soft_limit = 100.0f; // μV

    if (*left_sample > soft_limit)
        *left_sample = soft_limit + ((*left_sample - soft_limit) * 0.1f);
    else if (*left_sample < -soft_limit)
        *left_sample = -soft_limit + ((*left_sample + soft_limit) * 0.1f);

    if (*right_sample > soft_limit)
        *right_sample = soft_limit + ((*right_sample - soft_limit) * 0.1f);
    else if (*right_sample < -soft_limit)
        *right_sample = -soft_limit + ((*right_sample + soft_limit) * 0.1f);
}

/**
 * @brief Direct EEG sample processing function - bypasses semaphores
 */
void process_eeg_samples_direct(void)
{
    printf("SHRAVYA: 🚨🚨🚨 SIGNAL PROCESSING FUNCTION CALLED DIRECTLY! 🚨🚨🚨\r\n");
    printf("SHRAVYA: ✅ Processing EEG samples directly...\r\n");

    // Static variables to maintain state between calls
    static bool processing_initialized_direct = false;
    static eeg_raw_sample_t raw_samples[5];
    static uint32_t samples_read;
    static float filtered_left, filtered_right;

    // Initialize signal processing if not already done
    if (!processing_initialized_direct) {
        printf("SHRAVYA: 🔧 Initializing signal processing...\r\n");
        if (signal_processing_init() != FSP_SUCCESS) {
            printf("SHRAVYA: ❌ Signal processing initialization failed\r\n");
            return;
        }
        processing_initialized_direct = true;
        printf("SHRAVYA: ✅ Signal processing initialized\r\n");
    }

    printf("SHRAVYA: 📊 Getting EEG samples from buffer...\r\n");

    /* Get latest samples from acquisition buffer */
    if (eeg_get_samples(raw_samples, 5, &samples_read) == FSP_SUCCESS && samples_read > 0) {

        printf("SHRAVYA: 🎛️ Signal Processing - Got %u samples\r\n", samples_read);

        /* Process each sample through filtering pipeline */
        for (uint32_t i = 0; i < samples_read; i++) {
            // Process individual sample through complete pipeline
            process_eeg_sample(&raw_samples[i], &filtered_left, &filtered_right);

            /* Store in processing buffer */
            processing_state.processing_buffer_left[processing_state.buffer_index] = filtered_left;
            processing_state.processing_buffer_right[processing_state.buffer_index] = filtered_right;
            processing_state.buffer_index++;
        }

        /* Process features - immediate processing for real-time response */
        processing_state.buffer_ready = true;
        printf("SHRAVYA: ✅ Processing %u samples - features ready\r\n", samples_read);

        /* Reset buffer if it gets too full */
        if (processing_state.buffer_index >= PROCESSING_WINDOW_SIZE) {
            processing_state.buffer_index = OVERLAP_SIZE; // Reset with overlap

            /* Move overlapped data to beginning of buffer */
            memmove(processing_state.processing_buffer_left,
                   &processing_state.processing_buffer_left[PROCESSING_WINDOW_SIZE - OVERLAP_SIZE],
                   OVERLAP_SIZE * sizeof(float));
            memmove(processing_state.processing_buffer_right,
                   &processing_state.processing_buffer_right[PROCESSING_WINDOW_SIZE - OVERLAP_SIZE],
                   OVERLAP_SIZE * sizeof(float));
        }

        /* Update artifact tracking */
        if ((processing_state.samples_processed % 2500) == 0) { // Every 5 seconds
            processing_state.artifact_index++;
            processing_state.artifact_count[processing_state.artifact_index % ARTIFACT_HISTORY_SIZE] = 0;
        }

        printf("SHRAVYA: 📊 Processed samples: Left=%.2f μV, Right=%.2f μV\r\n",
               filtered_left, filtered_right);

        // Optional: Trigger feature extraction directly if needed
        // You can add feature extraction logic here or call it directly

        printf("SHRAVYA: ✅ Signal Processing complete - samples processed successfully!\r\n");

    } else {
        printf("SHRAVYA: ⚠️ No EEG samples available for processing\r\n");
    }

    printf("SHRAVYA: 🎯 Direct signal processing cycle complete!\r\n");
}


/**
 * @brief Process single EEG sample through complete pipeline
 */
void process_eeg_sample(const eeg_raw_sample_t *raw_sample, float *filtered_left, float *filtered_right)
{
    static float prev_left = 0.0f, prev_right = 0.0f;

    /* Convert ADC values to microvolts */
    float left_uv = convert_adc_to_voltage(raw_sample->left_channel);
    float right_uv = convert_adc_to_voltage(raw_sample->right_channel);

    /* Artifact detection */
    bool artifact_detected = detect_artifacts(left_uv, right_uv, prev_left, prev_right);

    if (artifact_detected)
    {
        /* Replace with interpolated values or zeros */
        left_uv = prev_left * 0.9f; // Simple interpolation
        right_uv = prev_right * 0.9f;

        /* Update artifact counter */
        processing_state.artifact_count[processing_state.artifact_index % ARTIFACT_HISTORY_SIZE]++;
    }

    /* Update baseline estimates */
    update_baseline(left_uv, right_uv);

    /* Apply digital filtering pipeline */

    /* Step 1: DC blocking (highpass 0.5Hz) */
    left_uv = process_biquad_cascade(processing_state.left_filters.highpass, left_uv);
    right_uv = process_biquad_cascade(processing_state.right_filters.highpass, right_uv);

    /* Step 2: 50Hz notch filter */
    left_uv = process_biquad_cascade(processing_state.left_filters.notch_50hz, left_uv);
    right_uv = process_biquad_cascade(processing_state.right_filters.notch_50hz, right_uv);

    /* Step 3: 60Hz notch filter */
    left_uv = process_biquad_cascade(processing_state.left_filters.notch_60hz, left_uv);
    right_uv = process_biquad_cascade(processing_state.right_filters.notch_60hz, right_uv);

    /* Step 4: Anti-aliasing lowpass (45Hz) */
    left_uv = process_biquad_cascade(processing_state.left_filters.lowpass, left_uv);
    right_uv = process_biquad_cascade(processing_state.right_filters.lowpass, right_uv);

    /* Step 5: Final signal conditioning */
    apply_signal_conditioning(&left_uv, &right_uv);

    /* Store results */
    *filtered_left = left_uv;
    *filtered_right = right_uv;

    /* Update previous values */
    prev_left = left_uv;
    prev_right = right_uv;

    processing_state.samples_processed++;
}

/**
 * @brief μT-Kernel Task: Signal Preprocessing (50Hz)
 * Priority: 15
 */
void task_signal_processing_entry(INT stacd, void *exinf)
{
    printf("SHRAVYA: 🚨 Signal processing task STARTED!\r\n");
        printf("SHRAVYA: 🚨 About to enter main loop!\r\n");
    (void)stacd;
    (void)exinf;

    eeg_raw_sample_t raw_samples[5]; // Process 10 samples at once (from 500Hz to 50Hz)
    uint32_t samples_read;
    float filtered_left, filtered_right;
    ER ercd;

    /* Initialize signal processing */
    if (signal_processing_init() != FSP_SUCCESS)
    {
        printf("SHRAVYA: ❌ Signal processing initialization failed\r\n");
        /* Initialization failed */
        while(1)
        {
            tk_dly_tsk(1000);
        }
    }

    printf("SHRAVYA: ✅ Signal processing task ready\r\n");

    while(1)
    {
        printf("SHRAVYA: 🎛️ Waiting for preprocessing semaphore...\r\n");
        printf("SHRAVYA: 🔍 DEBUG - Signal Processing Semaphore ID = %d\r\n", preprocessing_semaphore);
        ercd = tk_wai_sem(preprocessing_semaphore, 5000);  // 5 second timeout
        printf("SHRAVYA: 🔍 DEBUG - tk_wai_sem returned: %d\r\n", ercd);

        // MODIFIED: Better debug output
        if (ercd == E_OK) {
            printf("SHRAVYA: Signal Processing - Semaphore received! Result: %d\n", ercd);
        } else if (ercd == E_TMOUT) {
            printf("SHRAVYA: Signal Processing - Semaphore TIMEOUT! Result: %d\n", ercd);
        } else {
            printf("SHRAVYA: Signal Processing - Semaphore ERROR! Result: %d\n", ercd);
        }

        if (ercd != E_OK) {
            printf("SHRAVYA: Signal Processing - Semaphore failed: %d\n", ercd);
            // ✅ YIELD to higher priority tasks (like EEG)
            tk_dly_tsk(100);   // 100ms delay
            tk_rel_wai();      // Release waiting state
            tk_sus_tsk(tk_get_tid());  // Suspend self temporarily
            tk_rsm_tsk(tk_get_tid());  // Resume after EEG runs
            continue;
        }

        printf("SHRAVYA: Signal Processing - Starting processing...\n");

        /* Get latest samples from acquisition buffer */
        if (eeg_get_samples(raw_samples, 5, &samples_read) == FSP_SUCCESS && samples_read > 0)
        {
            // ✅ FIXED: Print AFTER getting samples_read value
            printf("SHRAVYA: 🎛️ Signal Processing - Got %u samples\r\n", samples_read);

            /* Process each sample through filtering pipeline */
            for (uint32_t i = 0; i < samples_read; i++)
            {
                process_eeg_sample(&raw_samples[i], &filtered_left, &filtered_right);

                /* Store in processing buffer */
                processing_state.processing_buffer_left[processing_state.buffer_index] = filtered_left;
                processing_state.processing_buffer_right[processing_state.buffer_index] = filtered_right;

                processing_state.buffer_index++;

                /* ALWAYS process features - immediate processing for real-time response */
                if (true)  // Process every batch of 5 samples
                {
                    processing_state.buffer_ready = true;
                    printf("SHRAVYA: ✅ Processing 5 samples - triggering features immediately\r\n");

                    /* Reset buffer if it gets too full */
                    if (processing_state.buffer_index >= PROCESSING_WINDOW_SIZE) {
                        processing_state.buffer_index = OVERLAP_SIZE; // Reset with overlap

                        /* Move overlapped data to beginning of buffer */
                        memmove(processing_state.processing_buffer_left,
                               &processing_state.processing_buffer_left[PROCESSING_WINDOW_SIZE - OVERLAP_SIZE],
                               OVERLAP_SIZE * sizeof(float));
                        memmove(processing_state.processing_buffer_right,
                               &processing_state.processing_buffer_right[PROCESSING_WINDOW_SIZE - OVERLAP_SIZE],
                               OVERLAP_SIZE * sizeof(float));
                    }
                }
            }

        }
        else
        {
            // ✅ ADDED: Debug log when no samples available
            printf("SHRAVYA: ⚠️ No EEG samples available\r\n");
        }

        /* Update artifact tracking */
        /* Update artifact tracking */
        if ((processing_state.samples_processed % 2500) == 0) // Every 5 seconds
        {
            processing_state.artifact_index++;
            processing_state.artifact_count[processing_state.artifact_index % ARTIFACT_HISTORY_SIZE] = 0;
        }

        /* ALWAYS trigger feature extraction after processing samples */
        printf("SHRAVYA: 📊 Signaling feature extraction...\r\n");
        tk_sig_sem(feature_extraction_semaphore, 1);

        /* WAIT for feature extraction to complete */
        printf("SHRAVYA: ⏳ Waiting for feature extraction to complete...\r\n");
        ER feat_wait = tk_wai_sem(features_ready_semaphore, TMO_FEVR);
        if (feat_wait == E_OK) {
            printf("SHRAVYA: ✅ Feature extraction completed\r\n");
        } else {
            printf("SHRAVYA: ⚠️ Feature extraction wait failed: %d\r\n", feat_wait);
        }

        // ADDED: Processing cycle completion debug
        tk_sig_sem(processed_semaphore, 1);
        printf("SHRAVYA: ✅ Signal Processing cycle complete\r\n");
    }
}

/**
 * @brief Direct EEG feature extraction function - based on cognitiveCLASSIFIER.c logic
 */
void extract_eeg_features_direct(void)
{
    printf("SHRAVYA: 🧠🧠🧠 FEATURE EXTRACTION CALLED DIRECTLY! 🧠🧠🧠\r\n");
    printf("SHRAVYA: 🔬 Extracting advanced cognitive features...\r\n");

    // Get processed signal buffers
    float *left_buffer, *right_buffer;
    uint32_t buffer_size;

    if (signal_processing_get_buffer(&left_buffer, &right_buffer, &buffer_size) != FSP_SUCCESS) {
        printf("SHRAVYA: ⚠️ Signal processing buffer not ready for feature extraction\r\n");
        return;
    }

    printf("SHRAVYA: 📊 Processing %u samples from signal buffer\r\n", buffer_size);

    /* ✅ EXACT LOGIC FROM YOUR COGNITIVE CLASSIFIER */

    // 1. Extract frequency domain features (FFT analysis)
    extract_frequency_features(left_buffer, right_buffer, (int)buffer_size);
    printf("SHRAVYA: ⚡ Frequency features extracted\r\n");

    // 2. Extract time domain features (statistical analysis)
    extract_time_domain_features(left_buffer, right_buffer, (int)buffer_size);
    printf("SHRAVYA: ⏱️ Time domain features extracted\r\n");

    // 3. Extract coherence features (inter-channel analysis)
    extract_coherence_features(left_buffer, right_buffer, (int)buffer_size);
    printf("SHRAVYA: 🔗 Coherence features extracted\r\n");

    // 4. Extract quality features (signal integrity)
    extract_quality_features(left_buffer, right_buffer, (int)buffer_size);
    printf("SHRAVYA: 🎛️ Quality features extracted\r\n");

    // ✅ EXACT OUTPUT FROM YOUR CLASSIFIER
    float focus_score = (current_features.beta_power > 0.000001f) ?
        (current_features.alpha_power / current_features.beta_power) : 0.0f;

    printf("SHRAVYA: ✅ Features extracted - Alpha: %.3f, Beta: %.3f, Focus Score: %.2f\r\n",
           current_features.alpha_power, current_features.beta_power, focus_score);

    printf("SHRAVYA: 📈 Time features - RMS: %.3f, Variance: %.3f, ZCR: %.3f\r\n",
           current_features.rms_amplitude, current_features.variance, current_features.zero_crossing_rate);

    printf("SHRAVYA: 🧠 Coherence - Cross-corr: %.3f, Alpha-coh: %.3f, Beta-coh: %.3f\r\n",
           current_features.cross_correlation, current_features.coherence_alpha, current_features.coherence_beta);

    printf("SHRAVYA: 🧠 Advanced EEG features - Delta: %.3f, Theta: %.3f, Gamma: %.3f\r\n",
           current_features.delta_power, current_features.theta_power, current_features.gamma_power);

    printf("SHRAVYA: ✅ Advanced feature extraction complete!\r\n");
}

/**
 * @brief Direct cognitive classification function - uses existing classifier
 */
void classify_cognitive_state_direct(void)
{
    printf("SHRAVYA: 🤖🤖🤖 AI CLASSIFICATION CALLED DIRECTLY! 🤖🤖🤖\r\n");

    // Use your existing classification logic from cognitiveCLASSIFIER.c
    cognitive_classification_t classification_result;

    // Forward propagation using your neural network
    float output_probabilities[OUTPUT_LAYER_SIZE];
    forward_propagation(&current_features, output_probabilities);

    // Determine dominant state using your existing logic
    classification_result.dominant_state = determine_dominant_state(output_probabilities);

    // Copy confidence scores
    for (int i = 0; i < OUTPUT_LAYER_SIZE; i++) {
        classification_result.confidence_scores[i] = output_probabilities[i];
    }

    // Calculate wellness score
    classification_result.overall_wellness_score =
        (output_probabilities[COGNITIVE_STATE_CALM] +
         output_probabilities[COGNITIVE_STATE_FOCUS]) / 2.0f;

    printf("SHRAVYA: 🧠 AI Classification Results:\r\n");
    printf("SHRAVYA: 🎯 Dominant State: %s (%.2f confidence)\r\n",
           (classification_result.dominant_state == COGNITIVE_STATE_FOCUS) ? "FOCUSED" :
           (classification_result.dominant_state == COGNITIVE_STATE_FATIGUE) ? "DROWSY" :
           (classification_result.dominant_state == COGNITIVE_STATE_STRESS) ? "STRESSED" :
           (classification_result.dominant_state == COGNITIVE_STATE_ANXIETY) ? "ANXIOUS" :
           (classification_result.dominant_state == COGNITIVE_STATE_CALM) ? "CALM" : "UNKNOWN",
           classification_result.confidence_scores[classification_result.dominant_state]);

    printf("SHRAVYA: 🎊 Wellness Score: %.2f/1.0\r\n", classification_result.overall_wellness_score);
    printf("SHRAVYA: ✅ AI classification complete!\r\n");

    // Check if intervention is needed
    if (intervention_required(&classification_result)) {
        printf("SHRAVYA: ⚠️ Intervention needed - triggering response\r\n");
        handle_intervention_trigger(&classification_result);
    }

    // ✅ FINAL STEP: Send to N8N
    printf("SHRAVYA: 📡 Triggering N8N communication...\r\n");
    send_to_n8n_direct(classification_result);
}

/**
 * @brief Direct N8N communication function - uses existing N8N logic
 */
void send_to_n8n_direct(cognitive_classification_t classification_result)
{
    printf("SHRAVYA: 📡📡📡 N8N COMMUNICATION CALLED DIRECTLY! 📡📡📡\r\n");

    // Create payload using your existing N8N format
    n8n_eeg_payload_t payload;
    memset(&payload, 0, sizeof(payload));

    // Fill payload with EXACT N8N format from your communicationN8N.c
    strcpy(payload.userid, "shravya_user_001");
    uint32_t current_time = R_FSP_SystemClockHzGet(FSP_PRIV_CLOCK_ICLK) / 1000;
    snprintf(payload.sessionid, sizeof(payload.sessionid), "session_%lu", (unsigned long)current_time);
    strcpy(payload.deviceid, "SHRAVYA_EEG_001");

    // Timestamp
    snprintf(payload.timestamp, sizeof(payload.timestamp), "2025-09-24T%02lu:%02lu:%02luZ",
             (unsigned long)((current_time / 3600) % 24),
             (unsigned long)((current_time / 60) % 60),
             (unsigned long)(current_time % 60));

    // Cognitive states (scale 0-10 as per your N8N format)
    payload.cognitive_states.focus = classification_result.confidence_scores[COGNITIVE_STATE_FOCUS] * 10.0f;
    payload.cognitive_states.stress = classification_result.confidence_scores[COGNITIVE_STATE_STRESS] * 10.0f;
    payload.cognitive_states.anxiety = classification_result.confidence_scores[COGNITIVE_STATE_ANXIETY] * 10.0f;
    payload.cognitive_states.fatigue = classification_result.confidence_scores[COGNITIVE_STATE_FATIGUE] * 10.0f;
    payload.cognitive_states.calm = classification_result.confidence_scores[COGNITIVE_STATE_CALM] * 10.0f;
    payload.cognitive_states.flowstate = (payload.cognitive_states.focus + payload.cognitive_states.calm) / 2.0f;

    // Frequency analysis from current features
    payload.frequency_analysis.delta_power = current_features.delta_power;
    payload.frequency_analysis.theta_power = current_features.theta_power;
    payload.frequency_analysis.alpha_power = current_features.alpha_power;
    payload.frequency_analysis.beta_power = current_features.beta_power;
    payload.frequency_analysis.gamma_power = current_features.gamma_power;

    // Signal quality
    payload.signal_quality.snr_db = current_features.snr_estimate;
    payload.signal_quality.artifact_detected = (current_features.signal_stability < 0.7f);
    payload.sampling_rate = 1000; // 1000 Hz from ADS1263

    // Build JSON and send using your existing functions
    char json_buffer[2048];
    build_n8n_json_payload(&payload, json_buffer, sizeof(json_buffer));

    fsp_err_t result = send_to_n8n_webhook(json_buffer);
    if (result == FSP_SUCCESS) {
        printf("SHRAVYA: ✅ Data sent to N8N successfully!\r\n");
        printf("SHRAVYA: 📊 Focus: %.1f, Stress: %.1f, Wellness: %.2f\r\n",
               payload.cognitive_states.focus, payload.cognitive_states.stress,
               classification_result.overall_wellness_score);
    } else {
        printf("SHRAVYA: ❌ N8N communication failed: %d\r\n", result);
    }

    printf("SHRAVYA: 🎯 COMPLETE SHRAVYA PIPELINE CYCLE FINISHED! 🎯\r\n");
    printf("SHRAVYA: 🚀 EEG → Signal → Features → AI → Cloud COMPLETE! 🚀\r\n");
}


/*
/**
 * @brief Get processing statistics
 */
void signal_processing_get_stats(uint32_t *samples_processed, uint32_t *total_artifacts, bool *is_ready)
{
    if (samples_processed) *samples_processed = processing_state.samples_processed;

    if (total_artifacts)
    {
        uint32_t total = 0;
        for (int i = 0; i < ARTIFACT_HISTORY_SIZE; i++)
        {
            total += processing_state.artifact_count[i];
        }
        *total_artifacts = total;
    }

    if (is_ready) *is_ready = processing_state.buffer_ready && processing_initialized;
}

/**
 * @brief Get filtered signal buffer for feature extraction
 */
fsp_err_t signal_processing_get_buffer(float **left_buffer, float **right_buffer, uint32_t *buffer_size)
{
    if (!processing_state.buffer_ready) return FSP_ERR_NOT_READY;

    if (left_buffer) *left_buffer = processing_state.processing_buffer_left;
    if (right_buffer) *right_buffer = processing_state.processing_buffer_right;
    if (buffer_size) *buffer_size = PROCESSING_WINDOW_SIZE;

    return FSP_SUCCESS;
}
