#include "hal_data.h"
#include "eegTYPES.h"
#include "cognitiveSTATES.h"
#include "mtk3_bsp2/include/tk/tkernel.h"
#include "shravyaCONFIG.h"
#include <math.h>
#include <string.h>

/* Audio Configuration */
#define SAMPLE_RATE_HZ              16000   // 16kHz for voice
#define AUDIO_BUFFER_SIZE           512     // 32ms at 16kHz
#define VOICE_DETECTION_THRESHOLD   1000    // Amplitude threshold
#define SILENCE_TIMEOUT_MS          2000    // 2 second silence timeout

/* Voice Command States */
typedef enum {
    VOICE_STATE_IDLE = 0,
    VOICE_STATE_LISTENING,
    VOICE_STATE_PROCESSING,
    VOICE_STATE_TIMEOUT
} voice_state_t;

/* Audio Processing Structure */
typedef struct {
    int16_t audio_buffer[AUDIO_BUFFER_SIZE];
    uint32_t buffer_index;
    bool voice_detected;
    voice_state_t current_state;
    uint32_t silence_timer;
    uint32_t total_voice_commands;
    float ambient_noise_level;
} audio_interface_t;

/* Global Variables */
static audio_interface_t audio_state;
static volatile bool audio_initialized = false;

/* Private Function Prototypes */
static void process_audio_sample(int16_t sample);
static bool detect_voice_activity(const int16_t *buffer, uint32_t size);
static void calculate_ambient_noise(const int16_t *buffer, uint32_t size);
static void trigger_voice_command(void);

/**
 * @brief Initialize INMP441 MEMS microphone via SSI peripheral
 */
fsp_err_t audio_interface_init(void)
{
    fsp_err_t err = FSP_SUCCESS;

    /* Initialize SSI interface for INMP441 - CORRECTED */
    err = R_SSI_Open(&g_ssi0_ctrl, &g_ssi0_cfg);
    if (FSP_SUCCESS != err) return err;

    /* SSI configuration is typically done in FSP configurator,
     * but can be modified at runtime if needed */

    /* Clear audio state */
    memset(&audio_state, 0, sizeof(audio_state));
    audio_state.current_state = VOICE_STATE_IDLE;
    audio_state.ambient_noise_level = 0.0f;

    audio_initialized = true;

    return FSP_SUCCESS;
}

/**
 * @brief Process single audio sample
 */
static void process_audio_sample(int16_t sample)
{
    /* Store sample in buffer */
    audio_state.audio_buffer[audio_state.buffer_index] = sample;
    audio_state.buffer_index = (audio_state.buffer_index + 1) % AUDIO_BUFFER_SIZE;

    /* Process when buffer is full */
    if (audio_state.buffer_index == 0) {
        /* Voice activity detection */
        bool voice_active = detect_voice_activity(audio_state.audio_buffer, AUDIO_BUFFER_SIZE);

        /* Update ambient noise level */
        calculate_ambient_noise(audio_state.audio_buffer, AUDIO_BUFFER_SIZE);

        /* State machine for voice commands */
        switch (audio_state.current_state) {
            case VOICE_STATE_IDLE:
                if (voice_active) {
                    audio_state.current_state = VOICE_STATE_LISTENING;
                    audio_state.silence_timer = 0;
                }
                break;

            case VOICE_STATE_LISTENING:
                if (voice_active) {
                    audio_state.silence_timer = 0;
                } else {
                    audio_state.silence_timer += 32; // 32ms per buffer
                    if (audio_state.silence_timer > SILENCE_TIMEOUT_MS) {
                        trigger_voice_command();
                        audio_state.current_state = VOICE_STATE_IDLE;
                    }
                }
                break;

            default:
                audio_state.current_state = VOICE_STATE_IDLE;
                break;
        }
    }
}

/**
 * @brief Detect voice activity using energy threshold
 */
static bool detect_voice_activity(const int16_t *buffer, uint32_t size)
{
    float energy = 0.0f;

    /* Calculate signal energy */
    for (uint32_t i = 0; i < size; i++) {
        energy += (float)(buffer[i] * buffer[i]);
    }

    energy = sqrtf(energy / size); // RMS energy

    /* Simple threshold-based VAD */
    return (energy > VOICE_DETECTION_THRESHOLD);
}

/**
 * @brief Calculate ambient noise level
 */
static void calculate_ambient_noise(const int16_t *buffer, uint32_t size)
{
    float rms = 0.0f;

    for (uint32_t i = 0; i < size; i++) {
        rms += (float)(buffer[i] * buffer[i]);
    }

    rms = sqrtf(rms / size);

    /* Exponential moving average */
    const float alpha = 0.1f;
    audio_state.ambient_noise_level = (1.0f - alpha) * audio_state.ambient_noise_level + alpha * rms;
}

/**
 * @brief Trigger voice command processing
 */
static void trigger_voice_command(void)
{
    audio_state.total_voice_commands++;

    /* Simple voice command recognition (placeholder) */
    /* In production, this would use speech recognition */

    /* Example: Trigger stress relief if ambient noise is high */
    if (audio_state.ambient_noise_level > 2000.0f) {
        trigger_haptic_pattern(COGNITIVE_STATE_STRESS);
    }
}

/**
 * @brief μT-Kernel Task: Audio Interface (16kHz)
 * Priority: 12 (High priority for real-time audio)
 */
void task_audio_interface_entry(INT stacd, void *exinf)
{
    (void)stacd;
    (void)exinf;

    int16_t audio_sample;
    ER ercd;

    /* Initialize audio interface */
    if (audio_interface_init() != FSP_SUCCESS) {
        while(1) tk_dly_tsk(1000);
    }

    /* Start SSI reception - CORRECTED */
    R_SSI_Start(&g_ssi0_ctrl);

    while(1) {
        /* Read audio sample from SSI - CORRECTED */
        size_t bytes_read;
        if (R_SSI_Read(&g_ssi0_ctrl, &audio_sample, 2, &bytes_read) == FSP_SUCCESS) {
            if (bytes_read == 2) { // 16-bit sample = 2 bytes
                process_audio_sample(audio_sample);
            }
        }

        /* Sleep for approximately 62.5μs (16kHz sampling rate) */
        tk_dly_tsk(1); // Minimum μT-Kernel delay
    }
}

/**
 * @brief Get audio interface statistics
 */
fsp_err_t get_audio_statistics(uint32_t *voice_commands, float *noise_level, bool *is_listening)
{
    if (voice_commands) *voice_commands = audio_state.total_voice_commands;
    if (noise_level) *noise_level = audio_state.ambient_noise_level;
    if (is_listening) *is_listening = (audio_state.current_state == VOICE_STATE_LISTENING);

    return FSP_SUCCESS;
}
